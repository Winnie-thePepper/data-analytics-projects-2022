{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This project will focus on data scrapping from tripadvisor reviews on Disneyland locations. Reviews for each locations will be converted into separate csv files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries to be used\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from csv import writer\n",
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "geolocater = Nominatim(user_agent = \"geoapiExercises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokyo Disneyland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab url from the website (tokyo disneyland reviews on tripadvisor)\n",
    "url = \"https://www.tripadvisor.com/Attraction_Review-g14134868-d320634-Reviews-Tokyo_Disneyland-Maihama_Urayasu_Chiba_Prefecture_Kanto.html\"\n",
    "# add headers found from stackoverflow to prevent code from stopping (https://stackoverflow.com/questions/71937012/python-web-scraper-not-working-for-tripadvisor)\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "page = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup variable\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "# create result variable that grabs each review cards\n",
    "results = soup.find_all(\"div\", class_=\"_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regex module to remove numbers from particular results\n",
    "pattern = r\"[0-9]\"\n",
    "review_num = 0\n",
    "# create csv file\n",
    "with open(\"Disneyland_Tokyo_Reviews_proto.csv\", \"w\", newline = \"\", encoding = \"utf8\") as f:\n",
    "    thewriter = writer(f)\n",
    "    header = [\"Review #\", \"Rating\", \"Year/Month\", \"Reviewer Location\", \"Review Title\", \"Review Text\"]\n",
    "    thewriter.writerow(header)\n",
    "    # grabbing variables from the data\n",
    "    for result in soup.select('#tab-data-qa-reviews-0 [data-automation=\"reviewCard\"]'):\n",
    "        rating = (result.select_one(\"svg[aria-label]\")[\"aria-label\"])[0:3] # wiped out the text part\n",
    "        if (result.find(\"div\", class_ = \"RpeCd\")) is not None:\n",
    "            year_month = (result.find(\"div\", class_ = \"RpeCd\")).text[0:8] # wiped out unnecessary text\n",
    "        else: \n",
    "            year_month = \"N/A\"\n",
    "        if result.find(\"div\", class_ = \"JINyA\") is not None:\n",
    "            reviewer_location = re.sub(pattern, \"\", (((result.find(\"div\", class_ = \"JINyA\")).text)[:-13])) # regrex module / :-13 used to wipe out some unnecessary text\n",
    "        else:\n",
    "            reviewer_location = \"N/A\"\n",
    "        if len(reviewer_location) < 3: # some reviews don't have location\n",
    "            reviewer_location = \"N/A\"\n",
    "        review_text = (result.find(\"div\", class_ = \"biGQs _P pZUbB KxBGd\")).text\n",
    "        review_title = (result.find(\"span\", class_ = \"yCeTE\")).text\n",
    "        review_num += 1\n",
    "        each_review = [review_num, rating, year_month, reviewer_location, review_title, review_text]\n",
    "        thewriter.writerow(each_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file is created and working. But the code only captures the first 10 reviews on the website. I will loop the code for 325 times as there are 3241 written reviews at the time (2022.10.21). The file including the first 10 reviews is named \"Disneyland_Tokyo_Reviews_proto.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tokyo Disneyland (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disneyland_Tokyo_Reviews.csv\", \"w\", newline = \"\", encoding = \"utf8\") as f:\n",
    "    thewriter = writer(f)\n",
    "    header = [\"Review #\", \"Rating\", \"Year/Month\", \"Reviewer Location\", \"Review Title\", \"Review Text\"]\n",
    "    thewriter.writerow(header)\n",
    "    review_num = 0\n",
    "    pattern = r\"[0-9]\"\n",
    "    for page in range (0, 3250, 10):\n",
    "        page = str(page)\n",
    "        if page == 0:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g14134868-d320634-Reviews-Tokyo_Disneyland-Maihama_Urayasu_Chiba_Prefecture_Kanto.html\"\n",
    "        else:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g14134868-d320634-Reviews-or\" + page + \"-Tokyo_Disneyland-Maihama_Urayasu_Chiba_Prefecture_Kanto.html\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"_c\")\n",
    "        for result in soup.select('#tab-data-qa-reviews-0 [data-automation=\"reviewCard\"]'):\n",
    "            rating = (result.select_one(\"svg[aria-label]\")[\"aria-label\"])[0:3] # wiped out the text part and converted into ints\n",
    "            if (result.find(\"div\", class_ = \"RpeCd\")) is not None:\n",
    "                year_month = (result.find(\"div\", class_ = \"RpeCd\")).text[0:8]\n",
    "            else:\n",
    "                year_month = \"N/A\"\n",
    "            if result.find(\"div\", class_ = \"JINyA\") is not None:\n",
    "                reviewer_location = re.sub(pattern, \"\", (((result.find(\"div\", class_ = \"JINyA\")).text)[:-13])) # regrex module / :-13 used to wipe out some unnecessary text\n",
    "            else:\n",
    "                reviewer_location = \"N/A\"\n",
    "            if len(reviewer_location) < 3: # some reviews don't have location\n",
    "                reviewer_location = \"N/A\"\n",
    "            review_text = (result.find(\"div\", class_ = \"biGQs _P pZUbB KxBGd\")).text\n",
    "            review_title = (result.find(\"span\", class_ = \"yCeTE\")).text\n",
    "            review_num += 1\n",
    "            each_review = [review_num, rating, year_month, reviewer_location, review_title, review_text]\n",
    "            thewriter.writerow(each_review)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every written reviews as of now (2022.10.21) are stored in a CSV file named \"Disneyland_tokyo_Revuews.csv\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Disneyland Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process will be done with other locations.\n",
    "\n",
    "Looped 1842 times (2022.10.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disneyland_Paris_Reviews.csv\", \"w\", newline = \"\", encoding = \"utf8\") as f:\n",
    "    thewriter = writer(f)\n",
    "    header = [\"Review #\", \"Rating\", \"Year/Month\", \"Reviewer Location\", \"Review Title\", \"Review Text\"]\n",
    "    thewriter.writerow(header)\n",
    "    review_num = 0\n",
    "    pattern = r\"[0-9]\"\n",
    "    for page in range (0, 18420, 10):\n",
    "        page = str(page)\n",
    "        if page == 0:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g226865-d189258-Reviews-Disneyland_Paris-Marne_la_Vallee_Seine_et_Marne_Ile_de_France.html\"\n",
    "        else:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g226865-d189258-Reviews-or\" + page + \"-Disneyland_Paris-Marne_la_Vallee_Seine_et_Marne_Ile_de_France.html\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"_c\")\n",
    "        for result in soup.select('#tab-data-qa-reviews-0 [data-automation=\"reviewCard\"]'):\n",
    "            rating = (result.select_one(\"svg[aria-label]\")[\"aria-label\"])[0:3] # wiped out the text part and converted into ints\n",
    "            if (result.find(\"div\", class_ = \"RpeCd\")) is not None:\n",
    "                year_month = (result.find(\"div\", class_ = \"RpeCd\")).text[0:8]\n",
    "            else:\n",
    "                year_month = \"N/A\"\n",
    "            if result.find(\"div\", class_ = \"JINyA\") is not None:\n",
    "                reviewer_location = re.sub(pattern, \"\", (((result.find(\"div\", class_ = \"JINyA\")).text)[:-13])) # regrex module / :-13 used to wipe out some unnecessary text\n",
    "            else:\n",
    "                reviewer_location = \"N/A\"\n",
    "            if len(reviewer_location) < 3: # some reviews don't have location\n",
    "                reviewer_location = \"N/A\"\n",
    "            review_text = (result.find(\"div\", class_ = \"biGQs _P pZUbB KxBGd\")).text\n",
    "            review_title = (result.find(\"span\", class_ = \"yCeTE\")).text\n",
    "            review_num += 1\n",
    "            each_review = [review_num, rating, year_month, reviewer_location, review_title, review_text]\n",
    "            thewriter.writerow(each_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hong Kong Disneyland\n",
    "\n",
    "Looped 1233 times (2022.10.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disneyland_HongKong_Reviews.csv\", \"w\", newline = \"\", encoding = \"utf8\") as f:\n",
    "    thewriter = writer(f)\n",
    "    header = [\"Review #\", \"Rating\", \"Year/Month\", \"Reviewer Location\", \"Review Title\", \"Review Text\"]\n",
    "    thewriter.writerow(header)\n",
    "    review_num = 0\n",
    "    pattern = r\"[0-9]\"\n",
    "    for page in range (0, 12330, 10):\n",
    "        page = str(page)\n",
    "        if page == 0:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g294217-d543602-Reviews-Hong_Kong_Disneyland-Hong_Kong.html\"\n",
    "        else:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g294217-d543602-Reviews-or\" + page + \"-Hong_Kong_Disneyland-Hong_Kong.html\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"_c\")\n",
    "        for result in soup.select('#tab-data-qa-reviews-0 [data-automation=\"reviewCard\"]'):\n",
    "            rating = (result.select_one(\"svg[aria-label]\")[\"aria-label\"])[0:3] # wiped out the text part and converted into ints\n",
    "            if (result.find(\"div\", class_ = \"RpeCd\")) is not None:\n",
    "                year_month = (result.find(\"div\", class_ = \"RpeCd\")).text[0:8]\n",
    "            else:\n",
    "                year_month = \"N/A\"\n",
    "            if result.find(\"div\", class_ = \"JINyA\") is not None:\n",
    "                reviewer_location = re.sub(pattern, \"\", (((result.find(\"div\", class_ = \"JINyA\")).text)[:-13])) # regrex module / :-13 used to wipe out some unnecessary text\n",
    "            else:\n",
    "                reviewer_location = \"N/A\"\n",
    "            if len(reviewer_location) < 3: # some reviews don't have location\n",
    "                reviewer_location = \"N/A\"\n",
    "            review_text = (result.find(\"div\", class_ = \"biGQs _P pZUbB KxBGd\")).text\n",
    "            review_title = (result.find(\"span\", class_ = \"yCeTE\")).text\n",
    "            review_num += 1\n",
    "            each_review = [review_num, rating, year_month, reviewer_location, review_title, review_text]\n",
    "            thewriter.writerow(each_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disney California Adventure Park\n",
    "\n",
    "Looped 1315 times (2022.10.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disneyland_California_Adventure_Park_Reviews.csv\", \"w\", newline = \"\", encoding = \"utf8\") as f:\n",
    "    thewriter = writer(f)\n",
    "    header = [\"Review #\", \"Rating\", \"Year/Month\", \"Reviewer Location\", \"Review Title\", \"Review Text\"]\n",
    "    thewriter.writerow(header)\n",
    "    review_num = 0\n",
    "    pattern = r\"[0-9]\"\n",
    "    for page in range (0, 13150, 10):\n",
    "        page = str(page)\n",
    "        if page == 0:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g29092-d186690-Reviews-Disney_California_Adventure_Park-Anaheim_California.html\"\n",
    "        else:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g29092-d186690-Reviews-or\" + page + \"-Disney_California_Adventure_Park-Anaheim_California.html\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"_c\")\n",
    "        for result in soup.select('#tab-data-qa-reviews-0 [data-automation=\"reviewCard\"]'):\n",
    "            rating = (result.select_one(\"svg[aria-label]\")[\"aria-label\"])[0:3] # wiped out the text part and converted into ints\n",
    "            if (result.find(\"div\", class_ = \"RpeCd\")) is not None:\n",
    "                year_month = (result.find(\"div\", class_ = \"RpeCd\")).text[0:8]\n",
    "            else:\n",
    "                year_month = \"N/A\"\n",
    "            if result.find(\"div\", class_ = \"JINyA\") is not None:\n",
    "                reviewer_location = re.sub(pattern, \"\", (((result.find(\"div\", class_ = \"JINyA\")).text)[:-13])) # regrex module / :-13 used to wipe out some unnecessary text\n",
    "            else:\n",
    "                reviewer_location = \"N/A\"\n",
    "            if len(reviewer_location) < 3: # some reviews don't have location\n",
    "                reviewer_location = \"N/A\"\n",
    "            review_text = (result.find(\"div\", class_ = \"biGQs _P pZUbB KxBGd\")).text\n",
    "            review_title = (result.find(\"span\", class_ = \"yCeTE\")).text\n",
    "            review_num += 1\n",
    "            each_review = [review_num, rating, year_month, reviewer_location, review_title, review_text]\n",
    "            thewriter.writerow(each_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Shanghai Disneyland\n",
    "Looped 141 times (2022.10.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Disneyland_Shanghai_Reviews.csv\", \"w\", newline = \"\", encoding = \"utf8\") as f:\n",
    "    thewriter = writer(f)\n",
    "    header = [\"Review #\", \"Rating\", \"Year/Month\", \"Reviewer Location\", \"Review Title\", \"Review Text\"]\n",
    "    thewriter.writerow(header)\n",
    "    review_num = 0\n",
    "    pattern = r\"[0-9]\"\n",
    "    for page in range (0, 1410, 10):\n",
    "        page = str(page)\n",
    "        if page == 0:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g308272-d10383031-Reviews-Shanghai_Disneyland-Shanghai.html\"\n",
    "        else:\n",
    "            url = \"https://www.tripadvisor.com/Attraction_Review-g308272-d10383031-Reviews-or\" + page + \"-Shanghai_Disneyland-Shanghai.html\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"_c\")\n",
    "        for result in soup.select('#tab-data-qa-reviews-0 [data-automation=\"reviewCard\"]'):\n",
    "            rating = (result.select_one(\"svg[aria-label]\")[\"aria-label\"])[0:3] # wiped out the text part and converted into ints\n",
    "            if (result.find(\"div\", class_ = \"RpeCd\")) is not None:\n",
    "                year_month = (result.find(\"div\", class_ = \"RpeCd\")).text[0:8]\n",
    "            else:\n",
    "                year_month = \"N/A\"\n",
    "            if result.find(\"div\", class_ = \"JINyA\") is not None:\n",
    "                reviewer_location = re.sub(pattern, \"\", (((result.find(\"div\", class_ = \"JINyA\")).text)[:-13])) # regrex module / :-13 used to wipe out some unnecessary text\n",
    "            else:\n",
    "                reviewer_location = \"N/A\"\n",
    "            if len(reviewer_location) < 3: # some reviews don't have location\n",
    "                reviewer_location = \"N/A\"\n",
    "            review_text = (result.find(\"div\", class_ = \"biGQs _P pZUbB KxBGd\")).text\n",
    "            review_title = (result.find(\"span\", class_ = \"yCeTE\")).text\n",
    "            review_num += 1\n",
    "            each_review = [review_num, rating, year_month, reviewer_location, review_title, review_text]\n",
    "            thewriter.writerow(each_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Changing location values as country\n",
    "The location variables are stored in cities, states, countries, and N/A values. Examples are shown on \"Disneyland_Tokyo_Reviews_proto.csv\". The following set of codes will convert them into countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Tokyo Disneyland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As experiencing timeout errors, I will split the attempts.\n",
    "keep_default_na was put to boolean value False as if it's true N/A value will turn into nan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (0, 500):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (500, 1000):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 500 - 1000, data from row 842 was reporting timeout error, so that value (Rhodes Town, Greece) was entered manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (1000, 1500):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 1000 - 1500, data from row 1370 was reporting timeout error, so that value (San Jose, California) was entered manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (1500, 2000):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1500 - 2000, data from row 1998 was reporting timeout error, so that value (Shanghai, China) was entered manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (2000, 2500):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2000 - 2500, data from row 2104 was reporting timeout error, so that value (Capital Federal District, Argentina) was entered manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (2500, 3000):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokyo = pd.read_csv(\"Disneyland_Tokyo_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (3000, 3241):\n",
    "    location_ = Tokyo[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Tokyo.loc[i, \"Reviewer Location\"] = location\n",
    "    Tokyo.to_csv(\"Disneyland_Tokyo_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3000 - 3241, data from row 3067 was reporting timeout error, so that value (Tokyo Prefecture, Japan) was entered manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Disneyland Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the process above, I discovered that the timeout error occurs only on certain addresses, so the process from now will be done in one code block, restarting from the middle when a timeout error occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris = pd.read_csv(\"Disneyland_Paris_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (0, 18407):\n",
    "    location_ = Paris[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Paris.loc[i, \"Reviewer Location\"] = location\n",
    "    Paris.to_csv(\"Disneyland_Paris_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row and values with timeout error written down:\n",
    "\n",
    "1215 Rhodes Town, Greece\n",
    "\n",
    "1723 Province of Seville, Spain \n",
    "\n",
    "2825 North Brabant Province, The Netherlands \n",
    "\n",
    "6322 Bristol, UK \n",
    "\n",
    "7400 Knowsley Village, UK \n",
    "\n",
    "9711 southeast england \n",
    "\n",
    "10017 Washingon D.C. \n",
    "\n",
    "10119 Kos Town, Greece \n",
    "\n",
    "11951 san jose, California\n",
    "\n",
    "14912 Springfield, MO \n",
    "\n",
    "15311 Chania Town, Greece \n",
    "\n",
    "15638 South of France\n",
    "\n",
    "16465 Saint Wenn, UK \n",
    "\n",
    "16646 U.S.A. East Coast\n",
    "\n",
    "18015 France , North East \n",
    "\n",
    "18189 Bucks, England "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Hong King Disneyland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HK = pd.read_csv(\"Disneyland_HongKong_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (0, 12330):\n",
    "    location_ = HK[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    HK.loc[i, \"Reviewer Location\"] = location\n",
    "    HK.to_csv(\"Disneyland_HongKong_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row and values with timeout error written down:\n",
    "\n",
    "86 Port de Sant Miguel, Spain \n",
    "\n",
    "4799 Province of Florence, Italy \n",
    "\n",
    "5491 Southern Norway, Norway \n",
    "\n",
    "8742 Labuan Town, Malaysia\n",
    "\n",
    "9774 St. Albans, UK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Disney California Adventure Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cal = pd.read_csv(\"Disneyland_California_Adventure_Park_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (0, 13127):\n",
    "    location_ = Cal[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    Cal.loc[i, \"Reviewer Location\"] = location\n",
    "    Cal.to_csv(\"Disneyland_California_Adventure_Park_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row and values with timeout error written down:\n",
    "\n",
    "1780 Washington, MO\n",
    "\n",
    "3896 Springfield, MO \n",
    "\n",
    "5562 Southern Calif. \n",
    "\n",
    "9316 small town, mt \n",
    "\n",
    "10345 Hawke Bay Region, New Zealand\n",
    "\n",
    "12665 North County San Diego \n",
    "\n",
    "12878 North Central Indiana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Shanghai Disneyland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH = pd.read_csv(\"Disneyland_Shanghai_Reviews.csv\", keep_default_na=False)\n",
    "for i in range (0, 1410):\n",
    "    location_ = SH[\"Reviewer Location\"][i]\n",
    "    if location_ == \"N/A\":\n",
    "        location = \"N/A\"\n",
    "    else:\n",
    "        if (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)) is not None:\n",
    "            if \"country\" in (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"]:\n",
    "                location = (geolocater.geocode(location_, exactly_one=True,language=\"en\", namedetails=True, addressdetails=True)).raw[\"address\"][\"country\"]\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "    SH.loc[i, \"Reviewer Location\"] = location\n",
    "    SH.to_csv(\"Disneyland_Shanghai_Reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Row and values with timeout error written down:\n",
    " \n",
    " 982 Colchester, UK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Insights\n",
    "Timeout errror on geocode occurs when the provided input value is somewhat strange for the computer to read (e.g. southwest california). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "- Cannot scrap the data automatically; should check how many reviews are there. \n",
    "- Could be better ways of coding.\n",
    "- Result crashes if review is not written in English\n",
    "- Scraping takes a long time\n",
    "- Should be availble to locate and clean them manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
